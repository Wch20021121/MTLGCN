{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import json"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:55:41.957915Z",
     "start_time": "2024-04-02T07:55:41.946815Z"
    }
   },
   "id": "4822477dbcd8dd78",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 0, '医术水平': 1, '相关服务': 2, '费用': 3, '医风医德': 4, '治疗方式': 5, '病情状态': 6, '心理': 7}\n",
      "{'O': 0, '相关服务': 1, '医风医德': 2, '医术水平': 3, '病情状态': 4, '治疗方式': 5, '心理': 6, '费用': 7}\n",
      "{'O': 0, '相关服务': 1, '医风医德': 2, '费用': 3, '病情状态': 4, '医术水平': 5, '治疗方式': 6, '心理': 7}\n",
      "{'O': 0, '相关服务': 1, '医风医德': 2, '治疗方式': 3, '病情状态': 4, '医术水平': 5, '费用': 6, '心理': 7}\n"
     ]
    }
   ],
   "source": [
    "def get_label_dict(file_name):\n",
    "    path = './process_data/'\n",
    "    label_dict={'O':0}\n",
    "    with open(path+file_name, 'r',encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        f.close()\n",
    "        for key in data:\n",
    "            for i in range(2, len(data[key]), 3):\n",
    "                if data[key][i] not in label_dict:\n",
    "                    label_dict[data[key][i]] = len(label_dict)\n",
    "    return label_dict\n",
    "x = get_label_dict('train_data.json')\n",
    "print(x)\n",
    "y = get_label_dict('test_data.json')\n",
    "print(y)\n",
    "z = get_label_dict('val_data.json')\n",
    "print(z)\n",
    "h = get_label_dict('same_data.json')\n",
    "print(h)"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-23T09:58:40.995277Z",
     "start_time": "2024-03-23T09:58:40.836387Z"
    }
   },
   "id": "initial_id",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 0, '医术水平': 1, '相关服务': 2, '费用': 3, '医风医德': 4, '治疗方式': 5, '病情状态': 6, '心理': 7}\n",
      "{'O': 0, '相关服务': 1, '医风医德': 2, '医术水平': 3, '病情状态': 4, '治疗方式': 5, '心理': 6, '费用': 7}\n",
      "{'O': 0, '相关服务': 1, '医风医德': 2, '费用': 3, '病情状态': 4, '医术水平': 5, '治疗方式': 6, '心理': 7}\n",
      "{'O': 0, '相关服务': 1, '医风医德': 2, '治疗方式': 3, '病情状态': 4, '医术水平': 5, '费用': 6, '心理': 7}\n"
     ]
    }
   ],
   "source": [
    "def write_label_dict(file_name):\n",
    "    label_dict={'O':0}\n",
    "    path = './process_data/'\n",
    "    with open(path+file_name, 'r',encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "        f.close()\n",
    "        for key in data:\n",
    "            for i in range(2, len(data[key]), 3):\n",
    "                if data[key][i] == '医生':\n",
    "                    data[key][i] = '医风医德'\n",
    "                if data[key][i] == '医院':\n",
    "                    data[key][i] = '相关服务'\n",
    "        for key in data:\n",
    "            for i in range(2, len(data[key]), 3):\n",
    "                if data[key][i] not in label_dict:\n",
    "                    label_dict[data[key][i]] = len(label_dict)\n",
    "    return data, label_dict\n",
    "train_data,x = write_label_dict('train_data.json')\n",
    "print(x)\n",
    "test_data,y = write_label_dict('test_data.json')\n",
    "print(y)\n",
    "val_data,z = write_label_dict('val_data.json')\n",
    "print(z)\n",
    "same_data,h = write_label_dict('same_data.json')\n",
    "print(h)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T09:52:57.387421Z",
     "start_time": "2024-03-23T09:52:57.197125Z"
    }
   },
   "id": "2ffa057b3ee5a765",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open('./process_data/train_data.json', 'w',encoding='utf-8') as f:\n",
    "    json.dump(train_data, f, ensure_ascii=False)\n",
    "    f.close()\n",
    "with open('./process_data/test_data.json', 'w',encoding='utf-8') as f:\n",
    "    json.dump(test_data, f, ensure_ascii=False)\n",
    "    f.close()\n",
    "with open('./process_data/val_data.json', 'w',encoding='utf-8') as f:\n",
    "    json.dump(val_data, f, ensure_ascii=False)\n",
    "    f.close()\n",
    "with open('./process_data/same_data.json', 'w',encoding='utf-8') as f:\n",
    "    json.dump(same_data, f, ensure_ascii=False)\n",
    "    f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T09:54:57.331460Z",
     "start_time": "2024-03-23T09:54:57.060898Z"
    }
   },
   "id": "dd68dd7f8985bc37",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open('./process_data/label_dict.json', 'w',encoding='utf-8') as f:\n",
    "    json.dump(h, f, ensure_ascii=False)\n",
    "    f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-23T09:58:26.451259Z",
     "start_time": "2024-03-23T09:58:26.432832Z"
    }
   },
   "id": "6f0aff941410e64d",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[71, 81, 37, 93, 29, 91, 2, 60, 67, 90]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "x = random.sample(range(1, 100), 10)\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T05:38:31.526772Z",
     "start_time": "2024-03-25T05:38:31.515582Z"
    }
   },
   "id": "1e58d49944f9423c",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15838\n",
      "23264\n",
      "39102\n"
     ]
    }
   ],
   "source": [
    "# 合并new_spark_data.json和train_data.json\n",
    "import json\n",
    "with open('./process_data/new_spark_data.json', 'r',encoding='utf-8') as f:\n",
    "    new_data = json.load(f)\n",
    "    f.close()\n",
    "with open('./process_data/train_data.json', 'r',encoding='utf-8') as f:\n",
    "    train_data = json.load(f)\n",
    "    f.close()\n",
    "print(len(new_data))\n",
    "print(len(train_data))\n",
    "for key in new_data:\n",
    "    train_data[key] = new_data[key]\n",
    "print(len(train_data))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T11:16:57.285502Z",
     "start_time": "2024-03-27T11:16:57.183154Z"
    }
   },
   "id": "6bef4df3d96dde21",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open('./process_data/new_train_data.json', 'w',encoding='utf-8') as f:\n",
    "    json.dump(train_data, f, ensure_ascii=False)\n",
    "    f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T11:17:49.597969Z",
     "start_time": "2024-03-27T11:17:49.457491Z"
    }
   },
   "id": "c1d644a846b5a2f0",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39101\n",
      "39101\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('./process_data/new_train_data.json', 'r',encoding='utf-8') as f:\n",
    "    new_train_data = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "for key in new_train_data:\n",
    "    if len(key) == 0:\n",
    "        x = key \n",
    "        print(1)\n",
    "print(len(new_train_data))\n",
    "print(len(new_train_data))\n",
    "with open('./process_data/new_train_data.json', 'w',encoding='utf-8') as f:\n",
    "    json.dump(new_train_data, f, ensure_ascii=False)\n",
    "    f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T13:17:20.347993Z",
     "start_time": "2024-03-27T13:17:20.059894Z"
    }
   },
   "id": "35ad7d02e1f0946a",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15837\n",
      "23264\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('./process_data/spark_AI/AI生成的语句/new_spark_data.json', 'r',encoding='utf-8') as f:\n",
    "    new_data = json.load(f)\n",
    "    f.close()\n",
    "with open('./process_data/train_data.json', 'r',encoding='utf-8') as f:\n",
    "    train_data = json.load(f)\n",
    "    f.close()\n",
    "print(len(new_data))\n",
    "print(len(train_data))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T02:40:35.033740Z",
     "start_time": "2024-03-30T02:40:34.936665Z"
    }
   },
   "id": "acaacc312dd8f343",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23364\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "def random_sample(data, num, train_data):\n",
    "    for text in data:\n",
    "        x = random.sample(range(1, num),1)\n",
    "        if x[0]%(num - 1) == 0:\n",
    "           train_data[text] = data[text]\n",
    "        else:\n",
    "            pass\n",
    "    return train_data\n",
    "#train_data = random_sample(new_data, 33, train_data) # 随机抽取1/33的数据\n",
    "def get_new_data(data, num, train_data):\n",
    "    cata = 0\n",
    "    while cata < num:\n",
    "        asp_list = []\n",
    "        for text in data:\n",
    "            if data[text] not in asp_list:\n",
    "               asp_list.append(data[text])\n",
    "               if text not in train_data:\n",
    "                   train_data[text] = data[text]\n",
    "                   cata += 1\n",
    "               else:\n",
    "                   pass\n",
    "            else:\n",
    "                pass\n",
    "            if cata == num:\n",
    "                break\n",
    "    return train_data\n",
    "train_data = get_new_data(new_data, 100, train_data) # 按照不同类型抽取数据\n",
    "print(len(train_data))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T02:41:06.295729Z",
     "start_time": "2024-03-30T02:41:06.275292Z"
    }
   },
   "id": "f25019537f83523c",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open('./process_data/spark_AI/100_spark_train_data.json', 'w',encoding='utf-8') as f:\n",
    "    json.dump(train_data, f, ensure_ascii=False)\n",
    "    f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T02:41:17.253389Z",
     "start_time": "2024-03-30T02:41:17.149264Z"
    }
   },
   "id": "ac57fda12ae6759f",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1615\n",
      "17451\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('./process_data/spark_AI/AI生成的语句/new_spark_data.json', 'r',encoding='utf-8') as f:\n",
    "    spark_data = json.load(f)\n",
    "    f.close()\n",
    "with open('./process_data/same_data.json', 'r',encoding='utf-8') as f:\n",
    "    same_data = json.load(f)\n",
    "    f.close()\n",
    "AI_data = {}\n",
    "for key in same_data:\n",
    "    if same_data[key][0] == -1:\n",
    "        AI_data[key] = same_data[key]\n",
    "    else:\n",
    "        continue\n",
    "print(len(AI_data))\n",
    "for key in spark_data:\n",
    "    AI_data[key] = spark_data[key]\n",
    "print(len(AI_data))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T13:49:09.947918Z",
     "start_time": "2024-03-31T13:49:09.849896Z"
    }
   },
   "id": "aab951a10ad758a7",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open('./process_data/spark_AI/AI识别的语句/AI_data.json', 'w',encoding='utf-8') as f:\n",
    "    json.dump(AI_data, f, ensure_ascii=False)\n",
    "    f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T13:50:24.906215Z",
     "start_time": "2024-03-31T13:50:24.842201Z"
    }
   },
   "id": "3eebd7af98777480",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with open('./process_data/same_data.json', 'r',encoding='utf-8') as f:\n",
    "    same_data = json.load(f)\n",
    "    f.close()\n",
    "negative_data = {}\n",
    "for key in same_data:\n",
    "    if same_data[key][0] == -1:\n",
    "        negative_data[key] = same_data[key]\n",
    "    else:\n",
    "        continue\n",
    "with open('./process_data/spark_AI/AI识别的语句/negative_data.json', 'w',encoding='utf-8') as f:\n",
    "    json.dump(negative_data, f, ensure_ascii=False)\n",
    "    f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-02T07:57:25.863695Z",
     "start_time": "2024-04-02T07:57:25.748350Z"
    }
   },
   "id": "5a6835840ff7c2e7",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4ed52629d36adf50"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
