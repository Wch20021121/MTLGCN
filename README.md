# 细粒度医疗评论模型 GCN +Bert+MTL
1. 项目简介: 本项目是基于GCN和Bert的细粒度医疗评论模型，主要用于对医疗评论进行情感分析，包括实体，实体所对应的情感和句子的整体情感。项目主要包括数据预处理、模型构建、模型训练和模型测试等部分。项目的主要贡献有：
   - 提出了一种基于GCN和Bert的细粒度医疗评论模型，用于对医疗评论进行情感分析，包括实体，实体所对应的情感和句子的整体情感。
   - 提出了一种多任务学习框架，用于同时预测实体，实体所对应的情感和句子的整体情感。
2. 项目结构: 
    - data: 存放数据集
    - Ltp_model: 存放LTP模型
    - result: 存放结果
    - process_data: 存放处理预处理的数据
    - README.md: 项目说明文档
    - test.py: 用于写测试代码：包括数据预处理、模型构建、模型训练和模型测试，可视化等部分
    - MTLGCN.py: 用于写模型代码：包括GCN模型和多任务学习框架
    - DataSets.py: 用于处理数据集，将它打包成一个个batch
    - DataLoader.py: 用于处理数据集，将其写到process_data文件夹下
3. 使用方式: 
    - 数据预处理: 运行DataLoader.py中的函数
    - 模型训练: 运行mian.py中的函数
    - 模型测试: 运行test.py中的函数

# 数据情感及分布
### 1. 数据情感分布
    - 实体的情感分布：
    - 句子的情感分布：
    - 整体的情感分布：

# 模型设想：
### A：借助LTP形成语句依存树，然后利用GCN对依存树进行编码：
    - 1.1：利用LTP对句子进行分词、词性标注、命名实体识别、依存句法分析等操作，得到句子的依存树
    - 1.2：利用GCN对依存树进行编码，得到句子的编码
### B：借助词典来构造邻接矩阵：
    - 2.1：利用词典来构造邻接矩阵
    - 2.2：利用Bert对邻接矩阵进行编码，得到句子的编码

# 模型构建：
### A：目录:
    -LTP_model: 存放LTP模型
    -process_data: 存放处理预处理的数据
    -result: 存放结果
    -process_result: 存放处理结果
    -DataSets_MTLGCN.py: 用于处理MTLGCN模型的数据集，将它打包成一个个batch
    -DataProcess.py: 用于处理数据集
    -MTLGCN.py: 用于写基准模型:bert-bi-lstm-crf,bert-gcn(分类出实体情感和总情感)
    -bert_bi_lstm_gcn.py: 用于写模型代码：包括GCN模型和多任务学习框架,用于分类出实体，实体情感和总情感
    -main.py: 用于写训练代码：包括数据预处理、模型构建、模型训练和模型测试，可视化等部分
    -bert_bi_lstm_gat.py: 用于写模型代码：包括GAT模型和多任务学习框架,用于分类出实体，实体情感和总情感

### B:如何调用：
    - 1.1：首先需要将数据集放到data文件夹下，处理成train_data.json,val_data.json,test_data.json,每一个
    个文件中是一个字典，字典的键是句子，值是一个列表，列表[总情感，实体，实体类型，实体情感，实体，实体类型，实体情感----]
    - 1.2：如果要运行基准模型，


# 模型结果归纳：
### A：模型的准确率：

  

